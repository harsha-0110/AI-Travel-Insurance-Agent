from fastapi import FastAPI
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
from app.agent.agent_executor import get_agent

app = FastAPI()

# Initialize the Multi-Agent Graph
agent = get_agent()

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
def chat(req: ChatRequest):
    print(f"User Message: {req.message}")
    
    # Pass the incoming text as a HumanMessage into the Graph state
    result = agent.invoke({"messages": [HumanMessage(content=req.message)]})
    
    # LangGraph returns the entire conversational state. 
    # Extract the very last message generated by the AI agent.
    final_message = result["messages"][-1].content
    
    return {"response": final_message}